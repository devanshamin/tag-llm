dataset: pubmed
feature_type: explanation
cache_dir: .cache
seed: 42

lm_encoder:
  model_name_or_path: avsolatorio/GIST-Embedding-v0
  model_library: sentence_transformer
  sentence_transformer_encoder_args:
    batch_size: 50
    show_progress_bar: True
    precision: float32
  cache_dir: ${cache_dir}

llm_online_engine:
  dataset_name: ${dataset}
  cache_dir: ${cache_dir}
  sampling_kwargs:
    max_tokens: 500
  #model: groq/mixtral-8x7b-32768 # https://litellm.vercel.app/docs/providers
  model: anthropic/claude-3-haiku-20240307

# llm_offline_engine:
#   dataset_name: ${dataset}
#   cache_dir: ${cache_dir}
#   sampling_kwargs:
#     max_tokens: 500
#     n: 1
#     temperature: 0.6
#     top_p: 0.9
#   model: meta-llama/Meta-Llama-3-8B-Instruct
#   batch_size: 100
#   engine_kwargs:
#     download_dir: ${cache_dir}
#     seed: ${seed}
#     max_model_len: 8192

gnn_model:
  conv_layer: SAGEConv # `torch_geometric.nn.conv` layer
  hidden_channels: 64
  num_layers: 4
  dropout: 0.1

gnn_trainer:
  epochs: 100
  lr: 0.0031622776601683794 # 10**-2.5
  weight_decay: 0.00001 # 10**-5

