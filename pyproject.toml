[tool.poetry]
name = "tag_llm"
version = "0.1.0"
description = "LLM-Enhanced Text-Attributed Graph Representation Learning"
authors = ["Devansh Amin <devanshamin97@gmail.com>"]
readme = "README.md"
repository = "https://github.com/devanshamin/tag-llm"

[tool.poetry.dependencies]
python = ">=3.9,<3.12"
pandas = "*"
requests = "*"
tqdm = "*"
python-dotenv = "^1.0.1"
gdown = "^5.2.0"
numpy = "*"
jinja2 = "*" # Prompt templates
tenacity = "*"
ogb = "^1.3.6" # Graph datasets
jsonargparse = {extras = ["omegaconf"], version = "^4.29.0"} # Combining dataclasses + YAML + CLI
diskcache = "^5.6.3" # Caching LLM responses
instructor = {extras = ["litellm"], version = "^1.3.2"} # Online LLM inference using provider APIs
transformers = "^4.41.2" # LM inference
sentence-transformers = "^3.0.1" # LM inference
datasets = "^2.19.2" # Loading LLM predictions from Hugging Face
vllm = { version = "0.5.0.post1", optional = true } # Offline LLM inference

[tool.poetry.extras]
llm_offline = ["vllm"]

[tool.poetry.group.dev.dependencies]
ruff = "^0.4.9"
pre-commit = "^3.7.1"
pytest = "^8.2.2"

[tool.poetry.scripts]
tag_llm_train = "tag_llm.train:main"

[tool.ruff]
line-length = 120

[tool.ruff.lint]
ignore = [
    "E731",  # Do not assign a lambda expression, use a def
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
